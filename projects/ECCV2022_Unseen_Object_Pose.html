
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Fusing Local Similarities for Retrieval-based 3D Orientation Estimation of Unseen Objects (ECCV 2022)</title>

<!-- Meta tags for search engines to crawl -->
<meta name="robots" content="index,follow">
<meta name="description" content="In this paper, we tackle the task of estimating the 3D orientation of previously-unseen objects from monocular images. This task contrasts with the one considered by most existing deep learning methods which typically assume that the testing objects have been observed during training. To handle the unseen objects, we follow a retrieval-based strategy and prevent the network from learning object-specific features by computing multi-scale local similarities between the query image and synthetically-generated reference images. We then introduce an adaptive fusion module that robustly aggregates the local similarities into a global similarity score of pairwise images. Furthermore, we speed up the retrieval process by developing a fast retrieval strategy. Our experiments on the LineMOD, LineMOD-Occluded, and T-LESS datasets show that our method yields a significantly better generalization to unseen objects than previous works.">
<meta name="keywords" content="Object 3D Orientation Estimation, Unseen Objects">
<link rel="author" href="https://sailor-z.github.io/">

<!-- Fonts and stuff -->
<link href="./ECCV2022_Unseen_Object_Pose/css.css" rel="stylesheet" type="text/css">
<link rel="stylesheet" type="text/css" href="./ECCV2022_Unseen_Object_Pose/project.css" media="screen">
<link rel="stylesheet" type="text/css" media="screen" href="./ECCV2022_Unseen_Object_Pose/iconize.css">
<script src="./ECCV2022_Unseen_Object_Pose/effect.js "></script>
<script async="" src="./ECCV2022_Unseen_Object_Pose/prettify.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script>
<script type="text/javascript"
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
</style></head>

<body><div style="visibility: hidden; overflow: hidden; position: absolute; top: 0px; height: 1px; width: auto; padding: 0px; border: 0px; margin: 0px; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal;"><div id="MathJax_Hidden"></div></div><div id="MathJax_Message" style="display: none;"></div>
  <div id="content">
    <div id="content-inner">

      <div class="section head">
        <h1>Fusing Local Similarities for Retrieval-based 3D Orientation Estimation of Unseen Objects</h1>
        <h1> ECCV 2022 </h1>

	<div class="authors">
    <a href="https://sailor-z.github.io/">Chen Zhao</a><sup>1</sup>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    <a href="https://yinlinhu.github.io/">Yinlin Hu</a><sup>1, 2</sup>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    <a href="https://people.epfl.ch/mathieu.salzmann">Mathieu Salzmann</a><sup>1, 2</sup>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

	</div>

	<div class="affiliations">
	  1. <a href="https://www.epfl.ch/labs/cvlab/">Computer Vision Laboratory, École polytechnique fédérale de Lausanne (EPFL)</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	  <br>
    2. <a href="https://clearspace.today/">ClearSpace SA</a>&nbsp;&nbsp;&nbsp;&nbsp;
	  <br>
	</div>

  <!-- <div class="venue">Conference on Neural Information Processing Systems (<a href="https://nips.cc/" target="_blank">NeurIPS</a>) 2020 </div> -->
  	<ul id="tabs">
  		<li>
  			<a href="https://arxiv.org/abs/2203.08472" name="#tab1">Paper</a>
  		</li>
  		<li>
  			<a href="https://github.com/sailor-z/Unseen_Object_Pose" name="#tab2">Code</a>
  		</li>
      <li>
  		<!--	<a href="https://youtu.be/tPEkLDSE_6g" name="#tab3">Video</a> -->
  		</li>
  		<li>
  		<!--	<a href="https://sailor-z.github.io/projects/CLNet.html#bibtex" name="#tab3">BibTex</a> -->
  		</li>
  	</ul>
    </div>

    <!-- <br> -->

<div class="section abstract">
	<h2>Abstract</h2>
  <hr/>
	<figure>
  <center><img src="./ECCV2022_Unseen_Object_Pose/intro.png" alt="Trulli" style="width:80%"></center><br>
  <center><figcaption>Fig. 1 - 3D Orientation Estimation for Unseen Objects.</figcaption></center>
</figure>
<h3>Background:</h3>
<p>Estimating the 3D orientation of objects from an image is pivotal to many computer vision and robotics tasks. Most learning-based methods assume that the training data and testing data contain exactly the same objects or similar objects from the same category. However, this assumption is often violated in real-world applications, such as robotic manipulation, where one would typically like the robotic arm to be able to handle previously-unseen objects without having to re-train the network for them.</p>
<h3>Our Contributions:</h3>
<ul>
<li>We estimate the 3D orientation of previously-unseen objects by introducing an image retrieval framework based on multi-scale local similarities.</li><br>
<li>We develop a similarity fusion module, robustly predicting an image similarity score from multi-scale pairwise feature maps.</li><br>
<li>We design a fast retrieval strategy that achieves a good trade-off between the 3D orientation estimation accuracy and efficiency.</li><br>
</ul>
	<!-- <p>
    The recent studies of knowledge distillation have discovered that ensembling the "dark knowledge" from multiple teachers (see <b>(a)</b>) or students (see <b>(b)</b>) contributes to creating better soft targets for training, but at the cost of significantly more computations and/or parameters. In this work, we present <b>BA</b>tch <b>K</b>nowledge <b>E</b>nsembling (<b>BAKE</b>) to produce refined soft targets for anchor images by propagating and ensembling the knowledge of the other samples in the same mini-batch (see <b>(c)</b>). Specifically, for each sample of interest, the propagation of knowledge is weighted in accordance with the inter-sample affinities, which are estimated on-the-fly with the current network. The propagated knowledge can then be ensembled to form a better soft target for distillation. In this way, our BAKE framework achieves online knowledge ensembling across multiple samples with only a single network. It requires minimal computational and memory overhead compared to existing knowledge ensembling methods. Extensive experiments demonstrate that the lightweight yet effective BAKE consistently boosts the classification performance of various architectures on multiple datasets, <i>e.g.</i>, a significant <mark><b>+1.2%</b></mark> gain of ResNet-50 on ImageNet with only <mark>+3.7%</mark> computational overhead and <mark>zero</mark> additional parameters. BAKE does not only improve the vanilla baselines, but also surpasses the single-network state-of-the-arts on all the benchmarks.
</p> -->
      </div>
 <div class="section method">
	<h2>Method Overview</h2>
  <hr/>
	<figure>
  <center><img src="./ECCV2022_Unseen_Object_Pose/framework.png" alt="Trulli" style="width:80%"></center><br>
  <figcaption>Fig. 2 - Network architecture. We extract multi-scale features from a locally normalized image. We then compute local similarities at each scale between the features of the source image and those of a reference one, and adaptively fuse them into a global similarity score.</figcaption>
  </div>

<br>

 <div class="section results">
	<h2>Results on LineMOD and LineMOD-O</h2>
  <hr/>
   <figure>
  <center><img src="./ECCV2022_Unseen_Object_Pose/linemod.jpeg" alt="Trulli" style="width:80%"></center><br>
  <center><figcaption>Fig. 4 - Experimental results on LineMOD and LineMOD-O</figcaption></center>
</figure>
      </div>

      <br>

 <div class="section examples">
	<h2>Visualization</h2>
  <hr/>
	<figure>
  <center><img src="./ECCV2022_Unseen_Object_Pose/visual.png" alt="Trulli" style="width:80%"></center><br>
  <center><figcaption>Fig. 5 - Qualitative Results in the presence of unseen objects.</center></figcaption>
</figure>
      </div>

<br>

<div class="section citation" ,="" id="bibtex">
	<h2>Citation</h2>
	<div class="section bibtex">
	  <pre>@article{zhao2022fusing,
          title={Fusing Local Similarities for Retrieval-based 3D Orientation Estimation of Unseen Objects},
          author={Zhao, Chen and Hu, Yinlin and Salzmann, Mathieu},
          journal={arXiv preprint arXiv:2203.08472},
          year={2022}
        }
}</pre>
	  </div>
      </div>

      <div class="section contact">
        <h2 id="contact">Contact</h2>
        <p>If you have any question, please contact Chen ZHAO at <strong>chen.zhao@epfl.ch</strong>.</p>
      </div>


</div></div><div style="position: absolute; width: 0px; height: 0px; overflow: hidden; padding: 0px; border: 0px; margin: 0px;"><div id="MathJax_Font_Test" style="position: absolute; visibility: hidden; top: 0px; left: 0px; width: auto; padding: 0px; border: 0px; margin: 0px; white-space: nowrap; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; font-size: 40px; font-weight: normal; font-style: normal; font-family: STIXSizeOneSym, sans-serif;"></div></div></body></html>
