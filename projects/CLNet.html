
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Progressive Correspondence Pruning by Consensus Learning</title>

<!-- Meta tags for search engines to crawl -->
<meta name="robots" content="index,follow">
<meta name="description" content="The recent studies of knowledge distillation have discovered that ensembling the 'dark knowledge' from multiple teachers or students contributes to creating better soft targets for training, but at the cost of significantly more computations and/or parameters. In this work, we present BAtch Knowledge Ensembling (BAKE) to produce refined soft targets for anchor images by propagating and ensembling the knowledge of the other samples in the same mini-batch. Specifically, for each sample of interest, the propagation of knowledge is weighted in accordance with the inter-sample affinities, which are estimated on-the-fly with the current network. The propagated knowledge can then be ensembled to form a better soft target for distillation. In this way, our BAKE framework achieves online knowledge ensembling across multiple samples with only a single network. It requires minimal computational and memory overhead compared to existing knowledge ensembling methods. Extensive experiments demonstrate that the lightweight yet effective BAKE consistently boosts the classification performance of various architectures on multiple datasets, e.g., a significant +1.2% gain of ResNet-50 on ImageNet with only +3.7% computational overhead and zero additional parameters. BAKE does not only improve the vanilla baselines, but also surpasses the single-network state-of-the-arts on all the benchmarks.">
<meta name="keywords" content="Representation Learning; Image Classification; Computer Vision; Deep Learning">
<link rel="author" href="https://sailor-z.github.io/">

<!-- Fonts and stuff -->
<link href="./CLNet/css.css" rel="stylesheet" type="text/css">
<link rel="stylesheet" type="text/css" href="./CLNet/project.css" media="screen">
<link rel="stylesheet" type="text/css" media="screen" href="./CLNet/iconize.css">
<script src="./CLNet/effect.js "></script>
<script async="" src="./CLNet/prettify.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script>
<script type="text/javascript"
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
</style></head>

<body><div style="visibility: hidden; overflow: hidden; position: absolute; top: 0px; height: 1px; width: auto; padding: 0px; border: 0px; margin: 0px; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal;"><div id="MathJax_Hidden"></div></div><div id="MathJax_Message" style="display: none;"></div>
  <div id="content">
    <div id="content-inner">

      <div class="section head">
        <h1>Progressive Correspondence Pruning by Consensus Learning</h1>

	<div class="authors">
    <a href="https://sailor-z.github.io/">Chen Zhao</a><sup>1*</sup>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	  <a href="https://yxgeee.github.io/">Yixiao Ge</a><sup>3*</sup>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    <a href="http://home.ustc.edu.cn/~zhufengx/">Feng Zhu</a><sup>2</sup>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    <a href="http://zhaorui.xyz/">Rui Zhao</a><sup>2,4</sup>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	  <a href="http://www.ee.cuhk.edu.hk/~hsli/">Hongsheng Li</a><sup>3</sup>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    <a href="https://people.epfl.ch/mathieu.salzmann">Mathieu Salzmann</a><sup>1</sup>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

	</div>

	<div class="affiliations">
	  1. <a href="https://www.epfl.ch/labs/cvlab/">Computer Vision Laboratory, École polytechnique fédérale de Lausanne (EPFL)</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	  <br>
    2. <a href="https://www.sensetime.com/en/">SenseTime Research</a>&nbsp;&nbsp;&nbsp;&nbsp;
	  <br>
    3. The Chinese University of Hong Kong</a>&nbsp;&nbsp;&nbsp;&nbsp;
    <br>
    4. Qing Yuan Research Institute, Shanghai Jiao Tong University
	  <!-- <br> -->

	</div>

  <!-- <div class="venue">Conference on Neural Information Processing Systems (<a href="https://nips.cc/" target="_blank">NeurIPS</a>) 2020 </div> -->
  	<ul id="tabs">
  		<li>
  			<a href="https://sailor-z.github.io/projects/CLNet/CLNet_ICCV2021.pdf" name="#tab1">Paper</a>
  		</li>
  		<li>
  			<a href="https://github.com/sailor-z/CLNet" name="#tab2">Code</a>
  		</li>
  		<li>
  			<a href="https://sailor-z.github.io/projects/CLNet.html#bibtex" name="#tab3">BibTex</a>
  		</li>
  	</ul>
    </div>

    <!-- <br> -->

<div class="section abstract">
	<h2>Abstract <a href="https://sailor-z.github.io/projects/CLNet/CLNet_ICCV2021.pdf" target="search_iframe">[Full Paper]</a></h2>
  <hr/>
	<figure>
  <center><img src="./CLNet/fig1.png" alt="Trulli" style="width:80%"></center><br>
  <center><figcaption>Fig. 1 - Progressive correspondence pruning via local-to-global consensus learning.</figcaption></center>
</figure>
<h3>Background:</h3>
<p>Correspondence selection aims to correctly select the consistent matches (inliers) from an initial set of putative correspondences. The selection is challenging since putative matches are typically extremely unbalanced, largely dominated by outliers, and the random distribution of such outliers further complicates the learning process for learning-based methods.</p>
<h3>Our Contributions:</h3>
<ul>
<li>We propose to progressively prune correspondences for better inlier identification, which alleviates the effects of unbalanced initial matches and random outlier distribution.</li><br>
<li>We introduce a local-to-global consensus learning network for robust correspondence pruning, achieved by establishing dynamic graphs on-the-fly and estimating both local and global consensus scores to prune correspondences.</li><br>
</ul>
	<!-- <p>
    The recent studies of knowledge distillation have discovered that ensembling the "dark knowledge" from multiple teachers (see <b>(a)</b>) or students (see <b>(b)</b>) contributes to creating better soft targets for training, but at the cost of significantly more computations and/or parameters. In this work, we present <b>BA</b>tch <b>K</b>nowledge <b>E</b>nsembling (<b>BAKE</b>) to produce refined soft targets for anchor images by propagating and ensembling the knowledge of the other samples in the same mini-batch (see <b>(c)</b>). Specifically, for each sample of interest, the propagation of knowledge is weighted in accordance with the inter-sample affinities, which are estimated on-the-fly with the current network. The propagated knowledge can then be ensembled to form a better soft target for distillation. In this way, our BAKE framework achieves online knowledge ensembling across multiple samples with only a single network. It requires minimal computational and memory overhead compared to existing knowledge ensembling methods. Extensive experiments demonstrate that the lightweight yet effective BAKE consistently boosts the classification performance of various architectures on multiple datasets, <i>e.g.</i>, a significant <mark><b>+1.2%</b></mark> gain of ResNet-50 on ImageNet with only <mark>+3.7%</mark> computational overhead and <mark>zero</mark> additional parameters. BAKE does not only improve the vanilla baselines, but also surpasses the single-network state-of-the-arts on all the benchmarks.
</p> -->
      </div>
 <div class="section method">
	<h2>Method Overview</h2>
  <hr/>
	<figure>
  <center><img src="./CLNet/fig2.png" alt="Trulli" style="width:50%"></center><br>
  <figcaption>Fig. 2 - We gradually prune the raw data into $\hat{N}$ candidates via $K$ pruning blocks guided by local-to-global consensus learning. A parametric model is then estimated, employing inliers identified among the $\hat{N}$ candidates. A full-size verification is further conducted based on the estimated model, yielding $N\times 1$ inlier/outlier predictions for the initial correspondences.</figcaption>
  <br>
  <figure>
  <center><img src="./CLNet/fig3.png" alt="Trulli" style="width:70%"></center><br>
  <center><figcaption>Fig. 3 - Detailed architecture of the proposed pruning block.</figcaption></center>
<br>
  </div>

<br>

 <div class="section results">
	<h2>Results on YFCC100M and SUN3D</h2>
  <hr/>
   <figure>
  <center><img src="./CLNet/results.png" alt="Trulli" style="width:100%"></center><br>
  <center><figcaption>Fig. 4 - Pose estimation on YFCC100M and SUN3D</figcaption></center>
</figure>
      </div>

      <br>

 <div class="section examples">
	<h2>Visualization</h2>
  <hr/>
	<figure>
  <center><img src="./CLNet/visual.png" alt="Trulli" style="width:60%"></center><br>
  <center><figcaption>Fig. 5 - Visualization of progressive pruning.</center></figcaption>
</figure>
      </div>

<!-- <div class="section demo">
	<h2>Public Video
    (Source:
    <a href="https://www.youtube.com/embed/77prEdxBuLE" target="search_iframe">YouTube</a> /
    <a href="https://player.bilibili.com/player.html?aid=970104264&cid=248579993&as_wide=1" target="search_iframe">bilibili</a>)
  </h2>

	<br>
	<center>
	  <iframe id="video" width="810" height="480" src="https://www.youtube.com/embed/77prEdxBuLE" name="search_iframe" frameborder="0" allowfullscreen></iframe>
	</center>
  <br>

</div> -->

<br>

<div class="section materials">
	<h2>Links</h2>
	<center>
	  <ul>

          <li class="grid">
	      <div class="griditem">
		<a href="https://sailor-z.github.io/projects/CLNet/CLNet_ICCV2021.pdf" target="_blank" class="imageLink"><img src="./CLNet/arxiv.png"></a><br>
		  <a href="https://sailor-z.github.io/projects/CLNet/CLNet_ICCV2021.pdf" target="_blank">Paper</a>
		</div>
	      </li>

        <!-- <li class="grid">
        <div class="griditem">
        <a href="../files/spcl_slides.pdf" target="_blank" class="imageLink"><img src="./spcl/cover.png"></a><br>
        <a href="../files/spcl_slides.pdf" target="_blank">Slides</a>
        </div>
        </li> -->

        <!-- <li class="grid">
        <div class="griditem">
        <a href="../files/spcl_poster.pdf" target="_blank" class="imageLink"><img src="./spcl/poster.png"></a><br>
        <a href="../files/spcl_poster.pdf" target="_blank">Poster</a>
        </div>
        </li> -->

        <li class="grid">
      <div class="griditem">
  <a href="https://github.com/sailor-z/CLNet" target="_blank" class="imageLink"><img src="./CLNet/code(1).png"></a><br>
    <a href="https://github.com/sailor-z/CLNet" target="_blank">Code and Models</a>
  </div>
      </li>

	    </ul>
	    </center>
	    </div>

<br>

<!-- <div class="section presentation">
	<h2>Presentation</h2>
	<center>
	  <ul> -->
            <!-- <li class="grid">
	      <div class="griditem">
		<a href="https://www.youtube.com/watch?v=BQZ5xKd5kis&t=1361" target="_blank" class="imageLink"><img src="./compounddomain/video.png"></a><br>
		  <a href="https://www.youtube.com/watch?v=BQZ5xKd5kis&t=1361" target="_blank">Video Recording</a>
		</div>
	      </li> -->


	    <!-- </ul>
	    </center>
	    </div>

<br> -->

<!-- <div class="section code">
	<h2>Code and Models</h2>
	<center>
	  <ul>

          <li class="grid">
	      <div class="griditem">
		<a href="https://github.com/yxgeee/MMT" target="_blank" class="imageLink"><img src="./mmt/code.png"></a><br>
		  <a href="https://github.com/yxgeee/MMT" target="_blank">Code and Models</a>
		</div>
	      </li>

	    </ul>
	    </center>
	    </div>

<br> -->

<!-- <div class="section data">
	<h2>Datasets</h2>
	<br>
	<center>
      	<a href="https://drive.google.com/open?id=1j7Nkfe6ZhzKFXePHdsseeeGI877Xu1yf" target="_blank" class="imageLink"><img src="./compounddomain/dataset.png" border="2" width="70%"></a><br>
      	<a href="https://drive.google.com/open?id=1j7Nkfe6ZhzKFXePHdsseeeGI877Xu1yf" target="_blank">Open Long-Tailed Datasets</a>
    </center>
    </div>

<br>-->

<div class="section blog">
	<h2>Blog</h2>
	<center>
	  <ul>

          <li class="grid">
	      <div class="griditem">
		<a href="https://zhuanlan.zhihu.com/p/394483122" target="_blank" class="imageLink"><img src="./CLNet/Zhihu_logo.png"></a><br>
		  <a href="https://zhuanlan.zhihu.com/p/394483122" target="_blank">Zhihu Blog (in Chinese)</a>
		</div>
	      </li>

	    </ul>
	    </center>
	    </div>

<br>

<div class="section citation" ,="" id="bibtex">
	<h2>Citation</h2>
	<div class="section bibtex">
	  <pre>@article{zhao2021consensus,
          title={Consensus-Guided Correspondence Denoising},
          author={Zhao, Chen and Ge, Yixiao and Yang, Jiaqi and Zhu, Feng and Zhao, Rui and Li, Hongsheng},
          journal={arXiv preprint arXiv:2101.00591},
          year={2021}
        }
}</pre>
	  </div>
      </div>

      <div class="section contact">
        <h2 id="contact">Contact</h2>
        <p>If you have any question, please contact Chen ZHAO at <strong>chen.zhao@epfl.ch</strong>.</p>
      </div>


</div></div><div style="position: absolute; width: 0px; height: 0px; overflow: hidden; padding: 0px; border: 0px; margin: 0px;"><div id="MathJax_Font_Test" style="position: absolute; visibility: hidden; top: 0px; left: 0px; width: auto; padding: 0px; border: 0px; margin: 0px; white-space: nowrap; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; font-size: 40px; font-weight: normal; font-style: normal; font-family: STIXSizeOneSym, sans-serif;"></div></div></body></html>
